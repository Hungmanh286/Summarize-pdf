{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10772721,"sourceType":"datasetVersion","datasetId":6683325},{"sourceId":10774465,"sourceType":"datasetVersion","datasetId":6684671}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install PyPDF2 sentence-transformers faiss-cpu openai numpy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:42:56.235990Z","iopub.execute_input":"2025-02-17T14:42:56.236420Z","iopub.status.idle":"2025-02-17T14:43:02.398263Z","shell.execute_reply.started":"2025-02-17T14:42:56.236378Z","shell.execute_reply":"2025-02-17T14:43:02.397287Z"}},"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.28.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.11.0a1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.28.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2, faiss-cpu\nSuccessfully installed PyPDF2-3.0.1 faiss-cpu-1.10.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import PyPDF2\n\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\ndef chunk_text(text, chunk_size=500):\n    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n    return chunks","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:02.399393Z","iopub.execute_input":"2025-02-17T14:43:02.399644Z","iopub.status.idle":"2025-02-17T14:43:02.772511Z","shell.execute_reply.started":"2025-02-17T14:43:02.399612Z","shell.execute_reply":"2025-02-17T14:43:02.771901Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport numpy as np\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\ndef generate_embeddings(chunks):\n    return model.encode(chunks)\n\ndef build_faiss_index(embeddings):\n    dimension = embeddings.shape[1]\n    index = faiss.IndexFlatL2(dimension)\n    index.add(embeddings)\n    return index\n\ndef save_faiss_index(index, file_path):\n    faiss.write_index(index, file_path)\n\ndef load_faiss_index(file_path):\n    return faiss.read_index(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:02.773862Z","iopub.execute_input":"2025-02-17T14:43:02.774113Z","iopub.status.idle":"2025-02-17T14:43:28.735365Z","shell.execute_reply.started":"2025-02-17T14:43:02.774083Z","shell.execute_reply":"2025-02-17T14:43:28.734518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cadf11b16e034468bf4633a9c226f432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aad847e3c20413db9ed88c9a1e0f5cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98bd46fc29684dbc99e865241cdc3da3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba84ee51a864efb85822cc048a3d51a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db11ae085a5421d80867bba012d12d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a483622d9ae4461f81619a8386a24503"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02fccd3460094be3ae4f7e1cde9a046d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef50708d433149dd8924ecc403ea91c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14a230a313c4f53b2366ea138453853"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf7a5750d48484691954a4717639a5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e33e6739d654a8c9a1e7477c59b4095"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\ndef retrieve_chunks(query, index, chunks, k=3):\n    query_embedding = model.encode([query])\n    distances, indices = index.search(query_embedding, k)\n    return [chunks[i] for i in indices[0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:28.736362Z","iopub.execute_input":"2025-02-17T14:43:28.736917Z","iopub.status.idle":"2025-02-17T14:43:28.741131Z","shell.execute_reply.started":"2025-02-17T14:43:28.736894Z","shell.execute_reply":"2025-02-17T14:43:28.740255Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import pipeline\n\n# Khởi tạo pipeline tóm tắt với Hugging Face\nsummarizer = pipeline(\"summarization\", model=\"openai-community/gpt2\")\n\ndef summarize_with_llm(text):\n    # Tóm tắt văn bản\n    summary = summarizer(text, max_length=512, min_length=30, do_sample=False, temperature=0.7)\n    return summary[0]['summary_text']\n\n# Test với đoạn văn bản\ntext = \"Machine learning is a method of data analysis that automates analytical model building...\"\nsummary = summarize_with_llm(text)\nprint(summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:28.741723Z","iopub.execute_input":"2025-02-17T14:43:28.741994Z","iopub.status.idle":"2025-02-17T14:43:39.211449Z","shell.execute_reply.started":"2025-02-17T14:43:28.741968Z","shell.execute_reply":"2025-02-17T14:43:39.210658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"368ac8fbf2c54bdda54659ffcf22c236"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b34a20354994f3eb46d8ad7eaaa5a10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"639080ab59204fe59c4c050e3b9353a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64315bfe55904a7da30711b178bf23e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65d690ff99654263b13ea423d53d20a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c082db1cbfe747e799e4e9b1118c1ed2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9cb688ecfba4f8cab48960c4ee88643"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nThe model 'GPT2LMHeadModel' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'Qwen2AudioForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\nYour max_length is set to 512, but your input_length is only 15. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Machine learning is a method of data analysis that automates analytical model building...\n\nThe Future of Machine Learning\n\nMachine learning is a method of data analysis that automates analytical model building. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can see. It is a way to build a model that is more accurate than the human eye can\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def chat_with_pdf(query, index, chunks):\n    relevant_chunks = retrieve_chunks(query, index, chunks)\n    context = \" \".join(relevant_chunks)\n    summary = summarize_with_llm(context)\n    return summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:39.212439Z","iopub.execute_input":"2025-02-17T14:43:39.212707Z","iopub.status.idle":"2025-02-17T14:43:39.216448Z","shell.execute_reply.started":"2025-02-17T14:43:39.212686Z","shell.execute_reply":"2025-02-17T14:43:39.215707Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\n\n# Paths\npdf_folder = \"/kaggle/input/data-pdf\"\nindex_path = \"/kaggle/working/pdf_index.faiss\"\n\n# Step 1: Extract and chunk text\npdf_path = os.path.join(pdf_folder, \"example.pdf\")\ntext = extract_text_from_pdf(pdf_path)\nchunks = chunk_text(text)\n\n# Step 2: Generate embeddings and build FAISS index\nembeddings = generate_embeddings(chunks)\nindex = build_faiss_index(embeddings)\nsave_faiss_index(index, index_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:39.217213Z","iopub.execute_input":"2025-02-17T14:43:39.217505Z","iopub.status.idle":"2025-02-17T14:43:40.140913Z","shell.execute_reply.started":"2025-02-17T14:43:39.217476Z","shell.execute_reply":"2025-02-17T14:43:40.140151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10d04c016f9b449e9ca7a5e493e44c70"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"query = \"Summary of this pdf file\"\nsummary = chat_with_pdf(query, index, chunks)\nprint(\"Summary:\", summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T14:43:40.142478Z","iopub.execute_input":"2025-02-17T14:43:40.142732Z","iopub.status.idle":"2025-02-17T14:43:40.854349Z","shell.execute_reply.started":"2025-02-17T14:43:40.142711Z","shell.execute_reply":"2025-02-17T14:43:40.853591Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf7269edc97243c2b671951c1af8818d"}},"metadata":{}},{"name":"stderr","text":"Your max_length is set to 512, but your input_length is only 426. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=213)\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Summary: rer would like to prove that it has manufactured the\nproduct. Anyone can freely identify the manufacturer of the\nproduct by viewing the ﬁrst owner recorded in PMC .\nC. Distribution management\nFig. 2 illustrates the ﬂow of distribution management.\nDistribution management consists of the following eight st eps:\nSteps 1 to 4 are the shipping process and Steps 5 to 8 are the\nreceiving process.\n1) The owner shares a secret token with the recipient by a\nsecure method.\n2) The owner encrypts the recipie hereum.org, [Online; accessed\n17-March-2020].\n[11] “ZoKrates,” https://github.com/Zokrates/ZoKrates , [Online; accessed 17-\nMarch-2020].\n[12] OECD, “Enhancing product recall effectiveness global ly,”OECD Sci-\nence, Technology and Industry Policy Papers , no. 58, Nov. 2018. . Pinto, “An introduction to the use of zk-SNARKs in bl ockchains,”\ninProceedings of Mathematical Research for Blockchain Econo my,\n2020, pp. 233–249.\n[8] B. WhiteHat, J. Baylina, and M. Bell´ es, “Baby jubjub ell iptic\ncurve,” https://iden3-docs.readthedocs.io/en/latest/ downloads/\n33717d75ab84e11313cc0d8a090b636f/Baby-Jubjub.pdf, [O nline;\naccessed 17-March-2020].\n[9] “Solidity,” https://solidity.readthedocs.io/, [Onl ine; accessed 17-March-\n2020].\n[10] “Remix - Ethereum IDE,” https://remix.ethereum.org/ , [Online; accessed 17-March-2020].\n[11] “Ethereum - Ethereum IDE,” https://emu.ethereum.org/ , [Online; accessed 17-March-2020].\n[12] “Ethereum - Ethereum IDE,” https://emu.ethereum.org/ , [Online; accessed 17-March-\n","output_type":"stream"}],"execution_count":8}]}